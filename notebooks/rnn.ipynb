{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Network\n",
        "\n",
        "This notebook will read in the merged dataset of session behavior, track IDs and track information, preprocess the data and perform an RNN model using an LSTM layer. \n",
        "\n",
        "The RNN model was chosen here because the sequence of the rows is important. The dataset is composed of several unique session IDs, each session consists of 20 rows. The data is reshaped during preprocessing to group the sessions. The LSTM layer is capable of learning long term dependencies, but predicting the following sequence based on the recent instances. "
      ],
      "metadata": {
        "id": "3EkW2clMtpce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries and read in the dataset"
      ],
      "metadata": {
        "id": "8B13-_vYvvwh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5eEYDkSUNzDX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from sklearn import metrics\n",
        "\n",
        "#from src folder\n",
        "from preprocessing import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('tracks_session_clean.csv', index_col=0)\n",
        "\n",
        "##There is a variety of session lengths. The sessions with 20 instances will be used.\n",
        "\n",
        "df = df.loc[df['session_length'] == 20]"
      ],
      "metadata": {
        "id": "RIo8SzLlN3H3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop columns\n",
        "\n",
        "To reduce making assumptions about the metadata, the acoustic vector columns were dropped. There are still plenty of music features available in the dataset that are more interpretable. Other dropped columns contained multicolinearity from the data exploration."
      ],
      "metadata": {
        "id": "kGrTINxVv-o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_col = ['session_length', 'date', 'track_id', 'hist_user_behavior_reason_start', 'beat_strength', 'dyn_range_mean',\n",
        "'acoustic_vector_0', 'acoustic_vector_1', 'acoustic_vector_2', 'acoustic_vector_3', 'acoustic_vector_4', 'acoustic_vector_5', 'acoustic_vector_6', 'acoustic_vector_7']\n",
        "\n",
        "df = df.drop(labels=drop_col, axis=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "g7UaO4z4N3QY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing\n",
        "\n",
        "Takes in a dataframe. Returns `train_features`, `test_features`, `train_labels`, and `test_labels`. It also scales the features, then reshapes them to fit the 3D LSTM layer. In this case, the 3D layer follows this format \n",
        "  (`num samples, num time-steps, num features`)"
      ],
      "metadata": {
        "id": "7EIXx4uMwUJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, test_features, train_labels, test_labels = preprocess(df)"
      ],
      "metadata": {
        "id": "dDxEnCc5svHy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_features.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_features.shape)\n",
        "print(test_labels.shape)"
      ],
      "metadata": {
        "id": "misIoEyLOPeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0d50a99-c764-4d9f-ad24-4b240b1c1116"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3500, 15, 32)\n",
            "(3500, 15, 1)\n",
            "(1566, 15, 32)\n",
            "(1566, 15, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build & train model"
      ],
      "metadata": {
        "id": "sEvh9mvzw3yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(32, activation='tanh'))\n",
        "model.add(layers.LSTM(16, activation='relu', return_sequences=True))\n",
        "model.add(layers.Dropout(.2))\n",
        "model.add(layers.Dense(16, activation='tanh'))\n",
        "model.add(layers.Dense(8, activation='relu'))\n",
        "\n",
        "#Binary outcome\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()], optimizer='Adam')"
      ],
      "metadata": {
        "id": "PTQzFB_UOqKn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_features, train_labels, epochs=200, verbose=2, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "114lFQU8OqU3",
        "outputId": "fdfa7543-14c7-4b9c-977f-87ce08a85c81"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "110/110 - 3s - loss: 0.6848 - accuracy: 0.5553 - precision: 0.5629 - recall: 0.8384 - 3s/epoch - 31ms/step\n",
            "Epoch 2/200\n",
            "110/110 - 1s - loss: 0.6779 - accuracy: 0.5712 - precision: 0.5815 - recall: 0.7729 - 597ms/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "110/110 - 1s - loss: 0.6735 - accuracy: 0.5843 - precision: 0.5947 - recall: 0.7556 - 626ms/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "110/110 - 1s - loss: 0.6702 - accuracy: 0.5895 - precision: 0.5993 - recall: 0.7541 - 614ms/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "110/110 - 1s - loss: 0.6682 - accuracy: 0.5931 - precision: 0.6025 - recall: 0.7539 - 614ms/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "110/110 - 1s - loss: 0.6667 - accuracy: 0.5948 - precision: 0.6041 - recall: 0.7533 - 663ms/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "110/110 - 1s - loss: 0.6658 - accuracy: 0.5954 - precision: 0.6046 - recall: 0.7536 - 631ms/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "110/110 - 1s - loss: 0.6646 - accuracy: 0.5977 - precision: 0.6074 - recall: 0.7493 - 642ms/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "110/110 - 1s - loss: 0.6637 - accuracy: 0.5986 - precision: 0.6093 - recall: 0.7431 - 611ms/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "110/110 - 1s - loss: 0.6619 - accuracy: 0.6015 - precision: 0.6119 - recall: 0.7432 - 548ms/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "110/110 - 1s - loss: 0.6611 - accuracy: 0.6027 - precision: 0.6121 - recall: 0.7484 - 598ms/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "110/110 - 1s - loss: 0.6609 - accuracy: 0.6026 - precision: 0.6124 - recall: 0.7463 - 579ms/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "110/110 - 1s - loss: 0.6595 - accuracy: 0.6054 - precision: 0.6150 - recall: 0.7463 - 572ms/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "110/110 - 1s - loss: 0.6579 - accuracy: 0.6096 - precision: 0.6189 - recall: 0.7461 - 593ms/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "110/110 - 1s - loss: 0.6563 - accuracy: 0.6105 - precision: 0.6200 - recall: 0.7450 - 580ms/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "110/110 - 1s - loss: 0.6559 - accuracy: 0.6099 - precision: 0.6191 - recall: 0.7467 - 772ms/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "110/110 - 1s - loss: 0.6546 - accuracy: 0.6109 - precision: 0.6201 - recall: 0.7465 - 839ms/epoch - 8ms/step\n",
            "Epoch 18/200\n",
            "110/110 - 1s - loss: 0.6533 - accuracy: 0.6128 - precision: 0.6210 - recall: 0.7506 - 713ms/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "110/110 - 1s - loss: 0.6524 - accuracy: 0.6150 - precision: 0.6233 - recall: 0.7495 - 585ms/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "110/110 - 1s - loss: 0.6501 - accuracy: 0.6158 - precision: 0.6244 - recall: 0.7481 - 543ms/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "110/110 - 1s - loss: 0.6495 - accuracy: 0.6186 - precision: 0.6260 - recall: 0.7531 - 574ms/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "110/110 - 1s - loss: 0.6485 - accuracy: 0.6182 - precision: 0.6267 - recall: 0.7482 - 583ms/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "110/110 - 1s - loss: 0.6467 - accuracy: 0.6225 - precision: 0.6302 - recall: 0.7507 - 560ms/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "110/110 - 1s - loss: 0.6463 - accuracy: 0.6206 - precision: 0.6292 - recall: 0.7472 - 574ms/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "110/110 - 1s - loss: 0.6448 - accuracy: 0.6224 - precision: 0.6307 - recall: 0.7482 - 562ms/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "110/110 - 1s - loss: 0.6440 - accuracy: 0.6239 - precision: 0.6324 - recall: 0.7470 - 550ms/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "110/110 - 1s - loss: 0.6429 - accuracy: 0.6252 - precision: 0.6337 - recall: 0.7467 - 570ms/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "110/110 - 1s - loss: 0.6428 - accuracy: 0.6254 - precision: 0.6342 - recall: 0.7460 - 561ms/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "110/110 - 1s - loss: 0.6403 - accuracy: 0.6289 - precision: 0.6382 - recall: 0.7431 - 574ms/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "110/110 - 1s - loss: 0.6388 - accuracy: 0.6303 - precision: 0.6388 - recall: 0.7467 - 559ms/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "110/110 - 1s - loss: 0.6390 - accuracy: 0.6297 - precision: 0.6382 - recall: 0.7465 - 581ms/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "110/110 - 1s - loss: 0.6375 - accuracy: 0.6328 - precision: 0.6409 - recall: 0.7484 - 537ms/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "110/110 - 1s - loss: 0.6361 - accuracy: 0.6314 - precision: 0.6392 - recall: 0.7498 - 557ms/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "110/110 - 1s - loss: 0.6352 - accuracy: 0.6327 - precision: 0.6410 - recall: 0.7477 - 572ms/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "110/110 - 1s - loss: 0.6354 - accuracy: 0.6340 - precision: 0.6421 - recall: 0.7487 - 578ms/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "110/110 - 1s - loss: 0.6330 - accuracy: 0.6369 - precision: 0.6453 - recall: 0.7473 - 815ms/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "110/110 - 1s - loss: 0.6318 - accuracy: 0.6386 - precision: 0.6465 - recall: 0.7493 - 824ms/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "110/110 - 1s - loss: 0.6313 - accuracy: 0.6386 - precision: 0.6457 - recall: 0.7527 - 646ms/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "110/110 - 1s - loss: 0.6294 - accuracy: 0.6398 - precision: 0.6488 - recall: 0.7450 - 560ms/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "110/110 - 1s - loss: 0.6289 - accuracy: 0.6402 - precision: 0.6487 - recall: 0.7474 - 571ms/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "110/110 - 1s - loss: 0.6281 - accuracy: 0.6407 - precision: 0.6501 - recall: 0.7440 - 544ms/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "110/110 - 1s - loss: 0.6271 - accuracy: 0.6422 - precision: 0.6500 - recall: 0.7502 - 569ms/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "110/110 - 1s - loss: 0.6267 - accuracy: 0.6434 - precision: 0.6518 - recall: 0.7482 - 517ms/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "110/110 - 1s - loss: 0.6244 - accuracy: 0.6460 - precision: 0.6532 - recall: 0.7528 - 535ms/epoch - 5ms/step\n",
            "Epoch 45/200\n",
            "110/110 - 1s - loss: 0.6245 - accuracy: 0.6465 - precision: 0.6547 - recall: 0.7494 - 555ms/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "110/110 - 1s - loss: 0.6238 - accuracy: 0.6441 - precision: 0.6529 - recall: 0.7467 - 614ms/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "110/110 - 1s - loss: 0.6235 - accuracy: 0.6449 - precision: 0.6545 - recall: 0.7439 - 576ms/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "110/110 - 1s - loss: 0.6227 - accuracy: 0.6467 - precision: 0.6562 - recall: 0.7446 - 625ms/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "110/110 - 1s - loss: 0.6218 - accuracy: 0.6473 - precision: 0.6568 - recall: 0.7450 - 559ms/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "110/110 - 1s - loss: 0.6198 - accuracy: 0.6492 - precision: 0.6585 - recall: 0.7461 - 557ms/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "110/110 - 1s - loss: 0.6195 - accuracy: 0.6519 - precision: 0.6605 - recall: 0.7490 - 533ms/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "110/110 - 1s - loss: 0.6187 - accuracy: 0.6518 - precision: 0.6609 - recall: 0.7469 - 562ms/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "110/110 - 1s - loss: 0.6190 - accuracy: 0.6502 - precision: 0.6604 - recall: 0.7432 - 566ms/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "110/110 - 1s - loss: 0.6180 - accuracy: 0.6520 - precision: 0.6625 - recall: 0.7423 - 549ms/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "110/110 - 1s - loss: 0.6175 - accuracy: 0.6543 - precision: 0.6654 - recall: 0.7408 - 674ms/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "110/110 - 1s - loss: 0.6164 - accuracy: 0.6541 - precision: 0.6648 - recall: 0.7423 - 805ms/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "110/110 - 1s - loss: 0.6138 - accuracy: 0.6555 - precision: 0.6661 - recall: 0.7430 - 811ms/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "110/110 - 1s - loss: 0.6140 - accuracy: 0.6555 - precision: 0.6655 - recall: 0.7453 - 517ms/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "110/110 - 1s - loss: 0.6124 - accuracy: 0.6574 - precision: 0.6687 - recall: 0.7410 - 536ms/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "110/110 - 1s - loss: 0.6126 - accuracy: 0.6569 - precision: 0.6669 - recall: 0.7454 - 543ms/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "110/110 - 1s - loss: 0.6121 - accuracy: 0.6569 - precision: 0.6657 - recall: 0.7494 - 529ms/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "110/110 - 1s - loss: 0.6154 - accuracy: 0.6544 - precision: 0.6659 - recall: 0.7398 - 553ms/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "110/110 - 1s - loss: 0.6163 - accuracy: 0.6541 - precision: 0.6658 - recall: 0.7388 - 551ms/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "110/110 - 1s - loss: 0.6121 - accuracy: 0.6580 - precision: 0.6675 - recall: 0.7475 - 555ms/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "110/110 - 1s - loss: 0.6092 - accuracy: 0.6616 - precision: 0.6724 - recall: 0.7444 - 597ms/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "110/110 - 1s - loss: 0.6057 - accuracy: 0.6653 - precision: 0.6745 - recall: 0.7508 - 546ms/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "110/110 - 1s - loss: 0.6068 - accuracy: 0.6633 - precision: 0.6731 - recall: 0.7482 - 570ms/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "110/110 - 1s - loss: 0.6057 - accuracy: 0.6631 - precision: 0.6724 - recall: 0.7498 - 552ms/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "110/110 - 1s - loss: 0.6037 - accuracy: 0.6649 - precision: 0.6743 - recall: 0.7499 - 569ms/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "110/110 - 1s - loss: 0.6040 - accuracy: 0.6645 - precision: 0.6754 - recall: 0.7452 - 562ms/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "110/110 - 1s - loss: 0.6029 - accuracy: 0.6654 - precision: 0.6752 - recall: 0.7489 - 535ms/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "110/110 - 1s - loss: 0.6042 - accuracy: 0.6648 - precision: 0.6752 - recall: 0.7469 - 592ms/epoch - 5ms/step\n",
            "Epoch 73/200\n",
            "110/110 - 1s - loss: 0.6020 - accuracy: 0.6663 - precision: 0.6761 - recall: 0.7491 - 504ms/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "110/110 - 1s - loss: 0.6015 - accuracy: 0.6670 - precision: 0.6776 - recall: 0.7470 - 562ms/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "110/110 - 1s - loss: 0.6010 - accuracy: 0.6683 - precision: 0.6803 - recall: 0.7434 - 627ms/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "110/110 - 1s - loss: 0.6010 - accuracy: 0.6683 - precision: 0.6792 - recall: 0.7467 - 792ms/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "110/110 - 1s - loss: 0.6004 - accuracy: 0.6680 - precision: 0.6776 - recall: 0.7505 - 862ms/epoch - 8ms/step\n",
            "Epoch 78/200\n",
            "110/110 - 1s - loss: 0.5994 - accuracy: 0.6675 - precision: 0.6792 - recall: 0.7439 - 603ms/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "110/110 - 1s - loss: 0.5997 - accuracy: 0.6686 - precision: 0.6790 - recall: 0.7483 - 584ms/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "110/110 - 1s - loss: 0.5976 - accuracy: 0.6697 - precision: 0.6805 - recall: 0.7473 - 544ms/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "110/110 - 1s - loss: 0.6009 - accuracy: 0.6669 - precision: 0.6778 - recall: 0.7460 - 567ms/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "110/110 - 1s - loss: 0.5981 - accuracy: 0.6699 - precision: 0.6809 - recall: 0.7469 - 585ms/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "110/110 - 1s - loss: 0.5977 - accuracy: 0.6701 - precision: 0.6797 - recall: 0.7513 - 537ms/epoch - 5ms/step\n",
            "Epoch 84/200\n",
            "110/110 - 1s - loss: 0.6004 - accuracy: 0.6661 - precision: 0.6783 - recall: 0.7418 - 545ms/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "110/110 - 1s - loss: 0.5986 - accuracy: 0.6686 - precision: 0.6794 - recall: 0.7472 - 546ms/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "110/110 - 1s - loss: 0.5994 - accuracy: 0.6666 - precision: 0.6799 - recall: 0.7386 - 538ms/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "110/110 - 1s - loss: 0.5949 - accuracy: 0.6726 - precision: 0.6837 - recall: 0.7476 - 556ms/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "110/110 - 1s - loss: 0.5933 - accuracy: 0.6751 - precision: 0.6846 - recall: 0.7536 - 553ms/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "110/110 - 1s - loss: 0.5938 - accuracy: 0.6738 - precision: 0.6849 - recall: 0.7485 - 563ms/epoch - 5ms/step\n",
            "Epoch 90/200\n",
            "110/110 - 1s - loss: 0.5932 - accuracy: 0.6715 - precision: 0.6815 - recall: 0.7506 - 585ms/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "110/110 - 1s - loss: 0.5931 - accuracy: 0.6738 - precision: 0.6852 - recall: 0.7471 - 547ms/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "110/110 - 1s - loss: 0.5921 - accuracy: 0.6742 - precision: 0.6842 - recall: 0.7519 - 554ms/epoch - 5ms/step\n",
            "Epoch 93/200\n",
            "110/110 - 1s - loss: 0.5910 - accuracy: 0.6739 - precision: 0.6844 - recall: 0.7500 - 562ms/epoch - 5ms/step\n",
            "Epoch 94/200\n",
            "110/110 - 1s - loss: 0.5902 - accuracy: 0.6771 - precision: 0.6876 - recall: 0.7514 - 544ms/epoch - 5ms/step\n",
            "Epoch 95/200\n",
            "110/110 - 1s - loss: 0.5884 - accuracy: 0.6789 - precision: 0.6888 - recall: 0.7539 - 692ms/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "110/110 - 1s - loss: 0.5884 - accuracy: 0.6790 - precision: 0.6890 - recall: 0.7538 - 778ms/epoch - 7ms/step\n",
            "Epoch 97/200\n",
            "110/110 - 1s - loss: 0.5903 - accuracy: 0.6769 - precision: 0.6874 - recall: 0.7513 - 739ms/epoch - 7ms/step\n",
            "Epoch 98/200\n",
            "110/110 - 1s - loss: 0.5904 - accuracy: 0.6755 - precision: 0.6862 - recall: 0.7503 - 543ms/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "110/110 - 1s - loss: 0.5886 - accuracy: 0.6782 - precision: 0.6902 - recall: 0.7479 - 524ms/epoch - 5ms/step\n",
            "Epoch 100/200\n",
            "110/110 - 1s - loss: 0.5871 - accuracy: 0.6783 - precision: 0.6880 - recall: 0.7543 - 553ms/epoch - 5ms/step\n",
            "Epoch 101/200\n",
            "110/110 - 1s - loss: 0.5849 - accuracy: 0.6810 - precision: 0.6901 - recall: 0.7573 - 565ms/epoch - 5ms/step\n",
            "Epoch 102/200\n",
            "110/110 - 1s - loss: 0.5874 - accuracy: 0.6802 - precision: 0.6899 - recall: 0.7551 - 569ms/epoch - 5ms/step\n",
            "Epoch 103/200\n",
            "110/110 - 1s - loss: 0.5863 - accuracy: 0.6790 - precision: 0.6888 - recall: 0.7544 - 574ms/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "110/110 - 1s - loss: 0.5866 - accuracy: 0.6801 - precision: 0.6884 - recall: 0.7592 - 571ms/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "110/110 - 1s - loss: 0.5847 - accuracy: 0.6809 - precision: 0.6901 - recall: 0.7569 - 573ms/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "110/110 - 1s - loss: 0.5866 - accuracy: 0.6807 - precision: 0.6902 - recall: 0.7558 - 540ms/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "110/110 - 1s - loss: 0.5848 - accuracy: 0.6805 - precision: 0.6906 - recall: 0.7543 - 507ms/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "110/110 - 1s - loss: 0.5827 - accuracy: 0.6821 - precision: 0.6916 - recall: 0.7567 - 538ms/epoch - 5ms/step\n",
            "Epoch 109/200\n",
            "110/110 - 1s - loss: 0.5858 - accuracy: 0.6792 - precision: 0.6894 - recall: 0.7533 - 556ms/epoch - 5ms/step\n",
            "Epoch 110/200\n",
            "110/110 - 1s - loss: 0.5840 - accuracy: 0.6831 - precision: 0.6920 - recall: 0.7586 - 558ms/epoch - 5ms/step\n",
            "Epoch 111/200\n",
            "110/110 - 1s - loss: 0.5821 - accuracy: 0.6845 - precision: 0.6941 - recall: 0.7573 - 535ms/epoch - 5ms/step\n",
            "Epoch 112/200\n",
            "110/110 - 1s - loss: 0.5812 - accuracy: 0.6844 - precision: 0.6945 - recall: 0.7560 - 503ms/epoch - 5ms/step\n",
            "Epoch 113/200\n",
            "110/110 - 1s - loss: 0.5796 - accuracy: 0.6861 - precision: 0.6964 - recall: 0.7561 - 560ms/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "110/110 - 1s - loss: 0.5781 - accuracy: 0.6873 - precision: 0.6968 - recall: 0.7588 - 524ms/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "110/110 - 1s - loss: 0.5806 - accuracy: 0.6859 - precision: 0.6957 - recall: 0.7576 - 595ms/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "110/110 - 1s - loss: 0.5778 - accuracy: 0.6872 - precision: 0.6956 - recall: 0.7620 - 808ms/epoch - 7ms/step\n",
            "Epoch 117/200\n",
            "110/110 - 1s - loss: 0.5779 - accuracy: 0.6874 - precision: 0.6966 - recall: 0.7598 - 831ms/epoch - 8ms/step\n",
            "Epoch 118/200\n",
            "110/110 - 1s - loss: 0.5754 - accuracy: 0.6900 - precision: 0.6994 - recall: 0.7605 - 584ms/epoch - 5ms/step\n",
            "Epoch 119/200\n",
            "110/110 - 1s - loss: 0.5790 - accuracy: 0.6861 - precision: 0.6958 - recall: 0.7576 - 558ms/epoch - 5ms/step\n",
            "Epoch 120/200\n",
            "110/110 - 1s - loss: 0.5789 - accuracy: 0.6866 - precision: 0.6959 - recall: 0.7593 - 571ms/epoch - 5ms/step\n",
            "Epoch 121/200\n",
            "110/110 - 1s - loss: 0.5870 - accuracy: 0.6801 - precision: 0.6904 - recall: 0.7533 - 522ms/epoch - 5ms/step\n",
            "Epoch 122/200\n",
            "110/110 - 1s - loss: 0.5794 - accuracy: 0.6883 - precision: 0.6998 - recall: 0.7539 - 595ms/epoch - 5ms/step\n",
            "Epoch 123/200\n",
            "110/110 - 1s - loss: 0.5795 - accuracy: 0.6870 - precision: 0.6973 - recall: 0.7566 - 560ms/epoch - 5ms/step\n",
            "Epoch 124/200\n",
            "110/110 - 1s - loss: 0.5770 - accuracy: 0.6905 - precision: 0.7006 - recall: 0.7586 - 510ms/epoch - 5ms/step\n",
            "Epoch 125/200\n",
            "110/110 - 1s - loss: 0.5750 - accuracy: 0.6920 - precision: 0.7011 - recall: 0.7622 - 542ms/epoch - 5ms/step\n",
            "Epoch 126/200\n",
            "110/110 - 1s - loss: 0.5740 - accuracy: 0.6910 - precision: 0.7015 - recall: 0.7581 - 541ms/epoch - 5ms/step\n",
            "Epoch 127/200\n",
            "110/110 - 1s - loss: 0.5748 - accuracy: 0.6911 - precision: 0.7014 - recall: 0.7585 - 515ms/epoch - 5ms/step\n",
            "Epoch 128/200\n",
            "110/110 - 1s - loss: 0.5737 - accuracy: 0.6922 - precision: 0.7017 - recall: 0.7610 - 553ms/epoch - 5ms/step\n",
            "Epoch 129/200\n",
            "110/110 - 1s - loss: 0.5744 - accuracy: 0.6916 - precision: 0.7013 - recall: 0.7602 - 544ms/epoch - 5ms/step\n",
            "Epoch 130/200\n",
            "110/110 - 1s - loss: 0.5739 - accuracy: 0.6909 - precision: 0.7006 - recall: 0.7600 - 588ms/epoch - 5ms/step\n",
            "Epoch 131/200\n",
            "110/110 - 1s - loss: 0.5747 - accuracy: 0.6898 - precision: 0.7020 - recall: 0.7528 - 561ms/epoch - 5ms/step\n",
            "Epoch 132/200\n",
            "110/110 - 1s - loss: 0.5721 - accuracy: 0.6949 - precision: 0.7045 - recall: 0.7623 - 558ms/epoch - 5ms/step\n",
            "Epoch 133/200\n",
            "110/110 - 1s - loss: 0.5779 - accuracy: 0.6899 - precision: 0.7008 - recall: 0.7562 - 592ms/epoch - 5ms/step\n",
            "Epoch 134/200\n",
            "110/110 - 1s - loss: 0.5718 - accuracy: 0.6946 - precision: 0.7049 - recall: 0.7600 - 562ms/epoch - 5ms/step\n",
            "Epoch 135/200\n",
            "110/110 - 1s - loss: 0.5693 - accuracy: 0.6972 - precision: 0.7069 - recall: 0.7632 - 607ms/epoch - 6ms/step\n",
            "Epoch 136/200\n",
            "110/110 - 1s - loss: 0.5692 - accuracy: 0.6958 - precision: 0.7053 - recall: 0.7631 - 817ms/epoch - 7ms/step\n",
            "Epoch 137/200\n",
            "110/110 - 1s - loss: 0.5760 - accuracy: 0.6900 - precision: 0.7014 - recall: 0.7550 - 819ms/epoch - 7ms/step\n",
            "Epoch 138/200\n",
            "110/110 - 1s - loss: 0.5718 - accuracy: 0.6930 - precision: 0.7027 - recall: 0.7613 - 605ms/epoch - 5ms/step\n",
            "Epoch 139/200\n",
            "110/110 - 1s - loss: 0.5689 - accuracy: 0.6955 - precision: 0.7058 - recall: 0.7608 - 558ms/epoch - 5ms/step\n",
            "Epoch 140/200\n",
            "110/110 - 1s - loss: 0.5677 - accuracy: 0.6983 - precision: 0.7096 - recall: 0.7597 - 544ms/epoch - 5ms/step\n",
            "Epoch 141/200\n",
            "110/110 - 1s - loss: 0.5672 - accuracy: 0.6968 - precision: 0.7066 - recall: 0.7626 - 576ms/epoch - 5ms/step\n",
            "Epoch 142/200\n",
            "110/110 - 1s - loss: 0.5682 - accuracy: 0.6988 - precision: 0.7095 - recall: 0.7615 - 576ms/epoch - 5ms/step\n",
            "Epoch 143/200\n",
            "110/110 - 1s - loss: 0.5802 - accuracy: 0.6888 - precision: 0.6997 - recall: 0.7557 - 559ms/epoch - 5ms/step\n",
            "Epoch 144/200\n",
            "110/110 - 1s - loss: 0.5790 - accuracy: 0.6884 - precision: 0.7010 - recall: 0.7509 - 574ms/epoch - 5ms/step\n",
            "Epoch 145/200\n",
            "110/110 - 1s - loss: 0.5693 - accuracy: 0.6977 - precision: 0.7088 - recall: 0.7599 - 526ms/epoch - 5ms/step\n",
            "Epoch 146/200\n",
            "110/110 - 1s - loss: 0.5691 - accuracy: 0.6965 - precision: 0.7077 - recall: 0.7589 - 567ms/epoch - 5ms/step\n",
            "Epoch 147/200\n",
            "110/110 - 1s - loss: 0.5681 - accuracy: 0.6985 - precision: 0.7085 - recall: 0.7631 - 554ms/epoch - 5ms/step\n",
            "Epoch 148/200\n",
            "110/110 - 1s - loss: 0.5663 - accuracy: 0.6993 - precision: 0.7083 - recall: 0.7662 - 535ms/epoch - 5ms/step\n",
            "Epoch 149/200\n",
            "110/110 - 1s - loss: 0.5653 - accuracy: 0.7002 - precision: 0.7105 - recall: 0.7631 - 532ms/epoch - 5ms/step\n",
            "Epoch 150/200\n",
            "110/110 - 1s - loss: 0.5654 - accuracy: 0.7000 - precision: 0.7083 - recall: 0.7683 - 570ms/epoch - 5ms/step\n",
            "Epoch 151/200\n",
            "110/110 - 1s - loss: 0.5645 - accuracy: 0.7010 - precision: 0.7099 - recall: 0.7672 - 561ms/epoch - 5ms/step\n",
            "Epoch 152/200\n",
            "110/110 - 1s - loss: 0.5678 - accuracy: 0.6983 - precision: 0.7093 - recall: 0.7602 - 568ms/epoch - 5ms/step\n",
            "Epoch 153/200\n",
            "110/110 - 1s - loss: 0.5677 - accuracy: 0.6975 - precision: 0.7084 - recall: 0.7601 - 546ms/epoch - 5ms/step\n",
            "Epoch 154/200\n",
            "110/110 - 1s - loss: 0.5653 - accuracy: 0.6998 - precision: 0.7094 - recall: 0.7647 - 539ms/epoch - 5ms/step\n",
            "Epoch 155/200\n",
            "110/110 - 1s - loss: 0.5620 - accuracy: 0.7017 - precision: 0.7119 - recall: 0.7643 - 568ms/epoch - 5ms/step\n",
            "Epoch 156/200\n",
            "110/110 - 1s - loss: 0.5653 - accuracy: 0.7002 - precision: 0.7093 - recall: 0.7662 - 792ms/epoch - 7ms/step\n",
            "Epoch 157/200\n",
            "110/110 - 1s - loss: 0.5649 - accuracy: 0.7008 - precision: 0.7126 - recall: 0.7599 - 807ms/epoch - 7ms/step\n",
            "Epoch 158/200\n",
            "110/110 - 1s - loss: 0.6001 - accuracy: 0.6726 - precision: 0.6827 - recall: 0.7507 - 614ms/epoch - 6ms/step\n",
            "Epoch 159/200\n",
            "110/110 - 1s - loss: 0.5880 - accuracy: 0.6832 - precision: 0.6909 - recall: 0.7620 - 538ms/epoch - 5ms/step\n",
            "Epoch 160/200\n",
            "110/110 - 1s - loss: 0.5754 - accuracy: 0.6918 - precision: 0.6997 - recall: 0.7653 - 533ms/epoch - 5ms/step\n",
            "Epoch 161/200\n",
            "110/110 - 1s - loss: 0.5714 - accuracy: 0.6974 - precision: 0.7052 - recall: 0.7685 - 558ms/epoch - 5ms/step\n",
            "Epoch 162/200\n",
            "110/110 - 1s - loss: 0.5670 - accuracy: 0.6990 - precision: 0.7087 - recall: 0.7644 - 547ms/epoch - 5ms/step\n",
            "Epoch 163/200\n",
            "110/110 - 1s - loss: 0.5669 - accuracy: 0.6997 - precision: 0.7098 - recall: 0.7636 - 550ms/epoch - 5ms/step\n",
            "Epoch 164/200\n",
            "110/110 - 1s - loss: 0.5664 - accuracy: 0.6997 - precision: 0.7109 - recall: 0.7607 - 545ms/epoch - 5ms/step\n",
            "Epoch 165/200\n",
            "110/110 - 1s - loss: 0.5640 - accuracy: 0.7023 - precision: 0.7115 - recall: 0.7670 - 565ms/epoch - 5ms/step\n",
            "Epoch 166/200\n",
            "110/110 - 1s - loss: 0.5637 - accuracy: 0.7047 - precision: 0.7139 - recall: 0.7684 - 505ms/epoch - 5ms/step\n",
            "Epoch 167/200\n",
            "110/110 - 1s - loss: 0.5600 - accuracy: 0.7045 - precision: 0.7138 - recall: 0.7680 - 562ms/epoch - 5ms/step\n",
            "Epoch 168/200\n",
            "110/110 - 1s - loss: 0.5595 - accuracy: 0.7021 - precision: 0.7112 - recall: 0.7672 - 544ms/epoch - 5ms/step\n",
            "Epoch 169/200\n",
            "110/110 - 1s - loss: 0.5612 - accuracy: 0.7037 - precision: 0.7122 - recall: 0.7698 - 576ms/epoch - 5ms/step\n",
            "Epoch 170/200\n",
            "110/110 - 1s - loss: 0.5598 - accuracy: 0.7054 - precision: 0.7150 - recall: 0.7677 - 559ms/epoch - 5ms/step\n",
            "Epoch 171/200\n",
            "110/110 - 1s - loss: 0.5606 - accuracy: 0.7052 - precision: 0.7159 - recall: 0.7648 - 560ms/epoch - 5ms/step\n",
            "Epoch 172/200\n",
            "110/110 - 1s - loss: 0.5665 - accuracy: 0.7011 - precision: 0.7132 - recall: 0.7591 - 550ms/epoch - 5ms/step\n",
            "Epoch 173/200\n",
            "110/110 - 1s - loss: 0.5630 - accuracy: 0.7060 - precision: 0.7177 - recall: 0.7628 - 536ms/epoch - 5ms/step\n",
            "Epoch 174/200\n",
            "110/110 - 1s - loss: 0.5649 - accuracy: 0.7019 - precision: 0.7137 - recall: 0.7604 - 563ms/epoch - 5ms/step\n",
            "Epoch 175/200\n",
            "110/110 - 1s - loss: 0.5610 - accuracy: 0.7052 - precision: 0.7146 - recall: 0.7682 - 521ms/epoch - 5ms/step\n",
            "Epoch 176/200\n",
            "110/110 - 1s - loss: 0.5586 - accuracy: 0.7059 - precision: 0.7158 - recall: 0.7675 - 753ms/epoch - 7ms/step\n",
            "Epoch 177/200\n",
            "110/110 - 1s - loss: 0.5594 - accuracy: 0.7050 - precision: 0.7163 - recall: 0.7634 - 822ms/epoch - 7ms/step\n",
            "Epoch 178/200\n",
            "110/110 - 1s - loss: 0.5557 - accuracy: 0.7095 - precision: 0.7190 - recall: 0.7703 - 697ms/epoch - 6ms/step\n",
            "Epoch 179/200\n",
            "110/110 - 1s - loss: 0.5562 - accuracy: 0.7107 - precision: 0.7200 - recall: 0.7714 - 528ms/epoch - 5ms/step\n",
            "Epoch 180/200\n",
            "110/110 - 1s - loss: 0.5560 - accuracy: 0.7114 - precision: 0.7214 - recall: 0.7699 - 575ms/epoch - 5ms/step\n",
            "Epoch 181/200\n",
            "110/110 - 1s - loss: 0.5565 - accuracy: 0.7117 - precision: 0.7216 - recall: 0.7705 - 544ms/epoch - 5ms/step\n",
            "Epoch 182/200\n",
            "110/110 - 1s - loss: 0.5590 - accuracy: 0.7059 - precision: 0.7182 - recall: 0.7614 - 541ms/epoch - 5ms/step\n",
            "Epoch 183/200\n",
            "110/110 - 1s - loss: 0.5600 - accuracy: 0.7071 - precision: 0.7169 - recall: 0.7680 - 531ms/epoch - 5ms/step\n",
            "Epoch 184/200\n",
            "110/110 - 1s - loss: 0.5610 - accuracy: 0.7053 - precision: 0.7159 - recall: 0.7654 - 540ms/epoch - 5ms/step\n",
            "Epoch 185/200\n",
            "110/110 - 1s - loss: 0.5565 - accuracy: 0.7101 - precision: 0.7206 - recall: 0.7681 - 542ms/epoch - 5ms/step\n",
            "Epoch 186/200\n",
            "110/110 - 1s - loss: 0.5553 - accuracy: 0.7103 - precision: 0.7196 - recall: 0.7711 - 566ms/epoch - 5ms/step\n",
            "Epoch 187/200\n",
            "110/110 - 1s - loss: 0.5561 - accuracy: 0.7076 - precision: 0.7176 - recall: 0.7681 - 571ms/epoch - 5ms/step\n",
            "Epoch 188/200\n",
            "110/110 - 1s - loss: 0.5648 - accuracy: 0.7039 - precision: 0.7145 - recall: 0.7645 - 541ms/epoch - 5ms/step\n",
            "Epoch 189/200\n",
            "110/110 - 1s - loss: 0.5603 - accuracy: 0.7053 - precision: 0.7141 - recall: 0.7698 - 543ms/epoch - 5ms/step\n",
            "Epoch 190/200\n",
            "110/110 - 1s - loss: 0.5593 - accuracy: 0.7070 - precision: 0.7187 - recall: 0.7635 - 523ms/epoch - 5ms/step\n",
            "Epoch 191/200\n",
            "110/110 - 1s - loss: 0.5599 - accuracy: 0.7057 - precision: 0.7150 - recall: 0.7687 - 593ms/epoch - 5ms/step\n",
            "Epoch 192/200\n",
            "110/110 - 1s - loss: 0.5629 - accuracy: 0.7065 - precision: 0.7186 - recall: 0.7624 - 534ms/epoch - 5ms/step\n",
            "Epoch 193/200\n",
            "110/110 - 1s - loss: 0.5588 - accuracy: 0.7075 - precision: 0.7188 - recall: 0.7647 - 546ms/epoch - 5ms/step\n",
            "Epoch 194/200\n",
            "110/110 - 1s - loss: 0.5559 - accuracy: 0.7089 - precision: 0.7190 - recall: 0.7683 - 525ms/epoch - 5ms/step\n",
            "Epoch 195/200\n",
            "110/110 - 1s - loss: 0.5566 - accuracy: 0.7096 - precision: 0.7205 - recall: 0.7668 - 548ms/epoch - 5ms/step\n",
            "Epoch 196/200\n",
            "110/110 - 1s - loss: 0.5554 - accuracy: 0.7094 - precision: 0.7182 - recall: 0.7717 - 610ms/epoch - 6ms/step\n",
            "Epoch 197/200\n",
            "110/110 - 1s - loss: 0.5589 - accuracy: 0.7082 - precision: 0.7187 - recall: 0.7671 - 762ms/epoch - 7ms/step\n",
            "Epoch 198/200\n",
            "110/110 - 1s - loss: 0.5537 - accuracy: 0.7104 - precision: 0.7208 - recall: 0.7687 - 822ms/epoch - 7ms/step\n",
            "Epoch 199/200\n",
            "110/110 - 1s - loss: 0.5565 - accuracy: 0.7086 - precision: 0.7182 - recall: 0.7696 - 550ms/epoch - 5ms/step\n",
            "Epoch 200/200\n",
            "110/110 - 1s - loss: 0.5722 - accuracy: 0.6986 - precision: 0.7108 - recall: 0.7576 - 562ms/epoch - 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5848a2cc70>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, precision, recall = model.evaluate(test_features, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwDtTK1CO0nB",
        "outputId": "60a3151a-b6a1-42ae-9b27-fbd58fdb5c74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49/49 [==============================] - 0s 3ms/step - loss: 0.7712 - accuracy: 0.5603 - precision: 0.5790 - recall: 0.6994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy)\n",
        "print(precision)\n",
        "print(recall)\n",
        "print((2*precision*recall)/(precision+recall)) #F1 score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ik7GJkB4ciX",
        "outputId": "e43097e3-2382-4b44-d6ea-81b19c9871b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5603235363960266\n",
            "0.5790258646011353\n",
            "0.69941246509552\n",
            "0.6335509471322516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretation"
      ],
      "metadata": {
        "id": "8AQAwXGcxTas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model learned the sequential nature of the dataset, which the logistic regression was unable to do. The precision score was 72% and 58% on train and test, respectively. We can consider this model slightly overfit, and may perform better once exposed to the original dataset and its noise. This model also included the musical features, which the other classifiers did not. "
      ],
      "metadata": {
        "id": "LhMBm-c4hFFR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EILfCMlPO0uw"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}